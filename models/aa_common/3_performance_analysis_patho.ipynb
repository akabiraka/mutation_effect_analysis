{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "home_dir = \"../../\"\n",
    "module_path = os.path.abspath(os.path.join(home_dir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from data_loader import get_merged_scores_unidirectional_df\n",
    "from utils.data_dicts import all_method_names\n",
    "from utils.performance_metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plans: \n",
    "#     For Pathogenic + Neutral/Baseline variants,\n",
    "\n",
    "#     1. Take all proteins containing pathogenic variants.\n",
    "#     2. Take all baseline variants for this protein set.\n",
    "#     3. If a protein does not have baseline variants, discard it. You will end up with X proteins.\n",
    "#     4. This is the new dataset â€“ count and list the number of proteins and pathogenic, likely-pathogenic, common, and rare variants.\n",
    "#     5. To calculate performance,\n",
    "#         1. sample one pathogenic variant and one neutral variant for each of the X proteins\n",
    "#         2. Calculate all the performance metrics.\n",
    "#         3. Repeat the above two steps ten times and compute mean & std.\n",
    "\n",
    "#     For Likely-pathogenic + Neutral variants, please repeat above steps with likely-pathogenic variants.\n",
    "#     Finally, combine two datasets (A, B), count and list the number of proteins and pathogenic, likely-pathogenic, common, and rare variants.\n",
    "#     Please send me the updated Performance metrics sheet and consolidated prediction sheet (with prediction scores) for the new combined (A, B) variants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"patho\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['clinvar_id', 'gene_name', 'gene_id', 'snp_id', 'mrna_acc_version',\n",
      "       'mrna_gi', 'prot_variant', 'prot_acc_version', '1indexed_prot_mt_pos',\n",
      "       'wt_aa', 'mt_aa', 'wt_aa_1letter', 'mt_aa_1letter', 'chrom_variant',\n",
      "       'chrom_acc_version', 'chrom_num', 'chrom_pos', 'ref_allele',\n",
      "       'alt_allele', 'class', 'metarnn', 'mvp', 'sift', 'polyphen2_HVAR',\n",
      "       'cadd_raw', 'revel', 'integrated_fitCons', 'phyloP17way_primate',\n",
      "       'phastCons17way_primate', 'bStatistic', 'esm1b_t33_650M_UR50S',\n",
      "       'esm1v_t33_650M_UR90S', 'esm2_t33_650M_UR50D', 'prottrans_bert_bfd',\n",
      "       'prottrans_albert_bfd', 'plus_rnn', 'prottrans_t5_xl_u50', 'mut_real',\n",
      "       'vespa', 'vespal', 'proteinbert', 'sequnet', 'protbert', 'unirep',\n",
      "       'conservation'],\n",
      "      dtype='object')\n",
      "(12263, 45)\n",
      "Likely-pathogenic    4804\n",
      "Rare                 3073\n",
      "Pathogenic           2499\n",
      "Common               1887\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "xresult_df = get_merged_scores_unidirectional_df(task, home_dir) # not using this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['clinvar_id', 'gene_name', 'gene_id', 'snp_id', 'mrna_acc_version',\n",
      "       'mrna_gi', 'prot_variant', 'prot_acc_version', '1indexed_prot_mt_pos',\n",
      "       'wt_aa', 'mt_aa', 'wt_aa_1letter', 'mt_aa_1letter', 'chrom_variant',\n",
      "       'chrom_acc_version', 'chrom_num', 'chrom_pos', 'ref_allele',\n",
      "       'alt_allele', 'class', 'metarnn', 'mvp', 'sift', 'polyphen2_HVAR',\n",
      "       'cadd_raw', 'revel', 'integrated_fitCons', 'phyloP17way_primate',\n",
      "       'phastCons17way_primate', 'bStatistic', 'esm1b_t33_650M_UR50S',\n",
      "       'esm1v_t33_650M_UR90S', 'esm2_t33_650M_UR50D', 'prottrans_bert_bfd',\n",
      "       'prottrans_albert_bfd', 'plus_rnn', 'prottrans_t5_xl_u50', 'mut_real',\n",
      "       'vespa', 'vespal', 'proteinbert', 'sequnet', 'protbert', 'unirep',\n",
      "       'conservation', 'SIFT', 'PolyPhen2', 'MetaRNN', 'Revel', 'MVP', 'CADD',\n",
      "       'Conservation\\n(PhastCons)', 'ESM1b', 'ESM1v', 'ESM2', 'Prottrans BERT',\n",
      "       'Prottrans T5', 'VESPA', 'ProteinBERT', 'Seq-Unet', 'ProtBERT',\n",
      "       'UniRep', 'PLUS-RNN', 'Conservation', 'VESPAI', 'Prottrans ALBERT',\n",
      "       'CHROM', 'POS', 'REF', 'ALT', 'aaPOS', 'transcript', 'protein_variant',\n",
      "       'uniqId_Cpos', 'uniqId_CposAA', 'uniqId_Tpos',\n",
      "       'am_pathogenicity_uniqId_Cpos', 'am_pathogenicity_uniqId_CposAA',\n",
      "       'am_pathogenicity_uniqId_Tpos'],\n",
      "      dtype='object')\n",
      "(12263, 79)\n",
      "Likely-pathogenic    4804\n",
      "Rare                 3073\n",
      "Pathogenic           2499\n",
      "Common               1887\n",
      "Name: class, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1776587/1568287625.py:1: DtypeWarning: Columns (13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  result_df = pd.read_csv(home_dir+f\"data/merged_predictions_with_alphamissense/dfPatho_addedAM.tsv\", sep=\"\\t\")\n"
     ]
    }
   ],
   "source": [
    "result_df = pd.read_csv(home_dir+f\"data/merged_predictions_with_alphamissense/dfPatho_addedAM.tsv\", sep=\"\\t\")\n",
    "print(result_df.columns)\n",
    "print(result_df.shape)\n",
    "print(result_df[\"class\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sift',\n",
       " 'polyphen2_HVAR',\n",
       " 'metarnn',\n",
       " 'revel',\n",
       " 'mvp',\n",
       " 'cadd_raw',\n",
       " 'integrated_fitCons',\n",
       " 'phyloP17way_primate',\n",
       " 'phastCons17way_primate',\n",
       " 'bStatistic',\n",
       " 'esm1b_t33_650M_UR50S',\n",
       " 'esm1v_t33_650M_UR90S',\n",
       " 'esm2_t33_650M_UR50D',\n",
       " 'prottrans_bert_bfd',\n",
       " 'prottrans_albert_bfd',\n",
       " 'plus_rnn',\n",
       " 'prottrans_t5_xl_u50',\n",
       " 'vespa',\n",
       " 'vespal',\n",
       " 'proteinbert',\n",
       " 'sequnet',\n",
       " 'protbert',\n",
       " 'unirep',\n",
       " 'conservation',\n",
       " 'am_pathogenicity_uniqId_Cpos',\n",
       " 'am_pathogenicity_uniqId_CposAA',\n",
       " 'am_pathogenicity_uniqId_Tpos',\n",
       " 'random_classifier']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_method_names = all_method_names + [\"am_pathogenicity_uniqId_Cpos\", \"am_pathogenicity_uniqId_CposAA\", \"am_pathogenicity_uniqId_Tpos\"] + [\"random_classifier\"]\n",
    "all_method_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos variants: (2499, 79), neg variants: (4960, 79)\n",
      "#-proteins\t754\n",
      "(1991, 79) (3173, 79)\n",
      "(754,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pathogenic    1991\n",
       "Rare          1900\n",
       "Common        1273\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pathogenic, Likely-pathogenic\n",
    "positive_cls, negative_cls, n_runs, n_samples, fill_missing_with_median = \"Pathogenic\", \"Neutral\", 10, None, False\n",
    "\n",
    "pos_cls_variants_df = result_df[result_df[\"class\"]==positive_cls]\n",
    "neg_cls_variants_df = result_df[((result_df[\"class\"]==\"Common\") | (result_df[\"class\"]==\"Rare\"))]\n",
    "print(f\"pos variants: {pos_cls_variants_df.shape}, neg variants: {neg_cls_variants_df.shape}\")\n",
    "\n",
    "pos_cls_prots = result_df[result_df[\"class\"]==positive_cls][\"prot_acc_version\"].unique()\n",
    "neg_cls_prots = result_df[((result_df[\"class\"]==\"Common\") | (result_df[\"class\"]==\"Rare\"))][\"prot_acc_version\"].unique()\n",
    "\n",
    "pos_cls_prots, neg_cls_prots = set(pos_cls_prots), set(neg_cls_prots)\n",
    "prots_set = pos_cls_prots.intersection(neg_cls_prots)\n",
    "# print(len(pos_cls_prots), len(neg_cls_prots), len(prots_set))\n",
    "print(f\"#-proteins\\t{len(prots_set)}\")\n",
    "\n",
    "pos_cls_variants_df = result_df[result_df[\"prot_acc_version\"].isin(prots_set) & (result_df[\"class\"]==positive_cls)]\n",
    "neg_cls_variants_df = result_df[result_df[\"prot_acc_version\"].isin(prots_set) & ((result_df[\"class\"]==\"Common\") | (result_df[\"class\"]==\"Rare\"))]\n",
    "print(pos_cls_variants_df.shape, neg_cls_variants_df.shape)\n",
    "\n",
    "variants_df = pd.concat([pos_cls_variants_df, neg_cls_variants_df])\n",
    "print(variants_df[\"prot_acc_version\"].unique().shape)\n",
    "\n",
    "\n",
    "variants_df[\"class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants_df.to_csv(home_dir+f\"data/performance_analysis_patho/data_{positive_cls}_vs_{negative_cls}.tsv\", sep=\"\\t\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pathogenic_cls_analysis_threshold(method_name, home_dir=\"\"):\n",
    "    patho_performance_metrics_df = pd.read_csv(home_dir + f\"data/performance_analysis_patho/patho_Pathogenic_vs_Neutral.tsv\", sep=\"\\t\")  \n",
    "    # performance_analysis, performance_analysis_minority_cls, performance_analysis_alphamissense, performance_analysis_alphamissense_minority_cls\n",
    "    patho_th_max = patho_performance_metrics_df[patho_performance_metrics_df[\"Models\\\\Metrics\"] == method_name][\"Th-max\"].values[1]\n",
    "    patho_th_max = patho_th_max.split(\"(\")[0]\n",
    "    patho_th_max = float(patho_th_max)\n",
    "    # print(f\"\\tComputed th from pathogenic-analysis: {patho_th_max}\")\n",
    "    return patho_th_max\n",
    "\n",
    "def fill_missing_values(df, method_name, with_median=False):\n",
    "    if with_median:\n",
    "        median = df[method_name].median()\n",
    "        df.loc[pd.isna(df[method_name]), method_name] = median  \n",
    "        # filling with median in the missing prediction score location\n",
    "    else: \n",
    "        df = df[~pd.isna(df[method_name])]  # taking only non-NAN values\n",
    "    return df\n",
    "    \n",
    "\n",
    "def compute_performance_metrics_for_patho(variants_df, method_name, positive_cls, negative_cls, n_runs, home_dir, fill_missing_with_median=False):\n",
    "    metric_scores = []\n",
    "    for i in range(n_runs):\n",
    "        if method_name == \"random_classifier\":\n",
    "            variants_df[method_name] = [random.uniform(0, 1) for i in range(variants_df.shape[0])]\n",
    "            \n",
    "        sampled_df = variants_df.groupby(by=\"prot_acc_version\").sample(1).copy()\n",
    "        sampled_df = fill_missing_values(sampled_df, method_name, fill_missing_with_median)            \n",
    "        sampled_df[\"pred\"] = sampled_df[method_name].copy()\n",
    "        sampled_df.loc[(sampled_df[\"class\"]==positive_cls), \"class_numeric\"] = 1\n",
    "        sampled_df.loc[(sampled_df[\"class\"]==negative_cls), \"class_numeric\"] = 0 \n",
    "        \n",
    "        if method_name in [\"phyloP17way_primate\", \"phastCons17way_primate\"]:\n",
    "            th_max = 0.5\n",
    "            sampled_df.loc[sampled_df[\"pred\"] >= th_max, \"pred\"] = 1\n",
    "            sampled_df.loc[sampled_df[\"pred\"] < th_max, \"pred\"] = 0\n",
    "\n",
    "        auc_roc_score, _ = get_auc_roc_score(sampled_df)\n",
    "        # ks_statistic, ks_pvalue = get_KS_test_score(sampled_df)\n",
    "        auc_pr_score, precisions, recalls, thresholds = get_auc_pr_score(sampled_df)\n",
    "        f1_max, th_max, precisions, recalls, thresholds = get_f1max_and_th(\n",
    "            precisions, recalls, thresholds\n",
    "        )\n",
    "\n",
    "        if positive_cls == \"Likely-pathogenic\":\n",
    "            th_max = get_pathogenic_cls_analysis_threshold(method_name, home_dir)\n",
    "        if method_name in [\"phyloP17way_primate\", \"phastCons17way_primate\"]:\n",
    "            th_max = 0.5\n",
    "\n",
    "        precision = get_precision_score(sampled_df, th_max)\n",
    "        recall = get_recall_score(sampled_df, th_max)\n",
    "        accuracy = get_accuracy_score(sampled_df, th_max)\n",
    "        balanced_accuracy = get_balanced_accuracy_score(sampled_df, th_max)\n",
    "        mcc = get_matthews_corrcoef(sampled_df, th_max)\n",
    "        \n",
    "        metric_scores.append(\n",
    "            [\n",
    "                auc_roc_score,\n",
    "                auc_pr_score,\n",
    "                f1_max,\n",
    "                th_max,\n",
    "                precision,\n",
    "                recall,\n",
    "                accuracy,\n",
    "                balanced_accuracy,\n",
    "                mcc,\n",
    "            ]\n",
    "        )\n",
    "        # print()\n",
    "        # if i==0: break\n",
    "    return metric_scores\n",
    "\n",
    "\n",
    "variants_df.loc[(result_df[\"class\"]==\"Common\") | (result_df[\"class\"]==\"Rare\"), \"class\"] = negative_cls # putting negative class level at Common and Rare level\n",
    "performance_scores_dict = {}\n",
    "\n",
    "for i, method_name in enumerate(all_method_names):\n",
    "    # method_name = \"esm1b_t33_650M_UR50S\"\n",
    "    performance_scores_dict[method_name] = compute_performance_metrics_for_patho(variants_df, method_name, positive_cls, negative_cls, n_runs, home_dir, fill_missing_with_median=True)\n",
    "    # if i==1:break\n",
    "write_metrics_outputs(performance_scores_dict, output_file=home_dir+f\"data/performance_analysis_patho/{task}_{positive_cls}_vs_{negative_cls}.tsv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hopper_variant_effect_analysis_mine",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
